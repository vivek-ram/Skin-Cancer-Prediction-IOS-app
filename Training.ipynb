{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Eager mode uses the CPU. Switching to the CPU.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Data visulisation and Data balancing and MetricsLibraries\n",
    "# ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import io \n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from skimage import img_as_ubyte\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import glob\n",
    "# ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Tensorflow Libraries\n",
    "# ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, InceptionResNetV2 , MobileNetV2 , ResNet152V2 , DenseNet201 , Xception , InceptionV3 , NASNetLarge\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "# ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Weight balancing Libraries\n",
    "# ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "from distutils.version import LooseVersion\n",
    "from collections import Counter\n",
    "# ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Checking GPU\n",
    "# ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "from tensorflow.python.compiler.mlcompute import mlcompute\n",
    "mlcompute.set_mlc_device(device_name='gpu')\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visulisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# ------------------------------------------------------------------------------\n",
    "# Train samples\n",
    "# ------------------------------------------------------------------------------\n",
    "akiec = glob.glob('/Users/vivekd/Downloads/d/datatree/train/akiec/*.*')\n",
    "bcc = glob.glob('/Users/vivekd/Downloads/d/datatree/train/bcc/*.*')\n",
    "bkl = glob.glob('/Users/vivekd/Downloads/d/datatree/train/bkl/*.*')\n",
    "df = glob.glob('/Users/vivekd/Downloads/d/datatree/train/df/*.*')\n",
    "mel = glob.glob('/Users/vivekd/Downloads/d/datatree/train/mel/*.*')\n",
    "nv = glob.glob('/Users/vivekd/Downloads/d/datatree/train/nv/*.*')\n",
    "vasc = glob.glob('/Users/vivekd/Downloads/d/datatree/train/vasc/*.*')\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Val samples\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "akiec_v = glob.glob('/Users/vivekd/Downloads/d/datatree/val/akiec/*.*')\n",
    "bcc_v = glob.glob('/Users/vivekd/Downloads/d/datatree/val/bcc/*.*')\n",
    "bkl_v = glob.glob('/Users/vivekd/Downloads/d/datatree/val/bkl/*.*')\n",
    "df_v = glob.glob('/Users/vivekd/Downloads/d/datatree/val/df/*.*')\n",
    "mel_v = glob.glob('/Users/vivekd/Downloads/d/datatree/val/mel/*.*')\n",
    "nv_v = glob.glob('/Users/vivekd/Downloads/d/datatree/val/nv/*.*')\n",
    "vasc_v = glob.glob('/Users/vivekd/Downloads/d/datatree/val/vasc/*.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[260, 409, 877, 91, 890, 5362, 111]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Train samples [260, 409, 877, 91, 890, 5362, 111]\n",
    "# Val samples [67, 105, 222, 24, 223, 1343, 31]\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "    'Diseases': ['akiec','bcc','bkl','df','mel','nv','vasc'],\n",
    "    'Train_Samples': [len(akiec),len(bcc),len(bkl),len(df),len(mel),len(nv),len(vasc)],\n",
    "    'Val_samples': [len(akiec_v),len(bcc_v),len(bkl_v),len(df_v),len(mel_v),len(nv_v),len(vasc_v)]\n",
    "})\n",
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "tidy = df1.melt(id_vars='Diseases').rename(columns=str.title)\n",
    "\n",
    "\n",
    "\n",
    "sns.barplot(x='Diseases', y='Value', hue='Variable', data=tidy, ax=ax1)\n",
    "sns.despine(fig)\n",
    "\n",
    "t = [len(akiec),len(bcc),len(bkl),len(df),len(mel),len(nv),len(vasc)]\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method to create custom images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_gen(name,disease,train,hflip,vflip,rot,angle,copy):\n",
    "    \n",
    "    if train==True:\n",
    "        augmented_path=\"/Users/vivekd/Downloads/d/c/train/\"+name        \n",
    "        for i in range(len(disease)):\n",
    "            img= cv2.imread(disease[i])\n",
    "            img= cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            img= cv2.resize(img,(224,224))\n",
    "            \n",
    "            \n",
    "            if copy==True:\n",
    "                new_image_path= \"%s/original_image_%s.jpg\" %(augmented_path, i)\n",
    "                transformed_image = img_as_ubyte(img)  #Convert an image to unsigned byte format, with values in [0, 255].\n",
    "                transformed_image=cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB) #convert image to RGB before saving it\n",
    "                cv2.imwrite(new_image_path, transformed_image)\n",
    "                            \n",
    "\n",
    "            if hflip==True:\n",
    "                new_image_path= \"%s/hflip_image_%s.jpg\" %(augmented_path, i)\n",
    "                transformed_image= np.fliplr(img)\n",
    "                transformed_image = img_as_ubyte(transformed_image)  #Convert an image to unsigned byte format, with values in [0, 255].\n",
    "                transformed_image=cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB) #convert image to RGB before saving it\n",
    "                cv2.imwrite(new_image_path, transformed_image)\n",
    "\n",
    "            if vflip==True:\n",
    "                new_image_path= \"%s/vflip_image_%s.jpg\" %(augmented_path, i)\n",
    "                transformed_image= np.flipud(img)\n",
    "                transformed_image = img_as_ubyte(transformed_image)  #Convert an image to unsigned byte format, with values in [0, 255].\n",
    "                transformed_image=cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB) #convert image to RGB before saving it\n",
    "                cv2.imwrite(new_image_path, transformed_image)\n",
    "                \n",
    "            if rot==True:\n",
    "                if angle == 180:\n",
    "                    new_image_path= \"%s/rot180_image_%s.jpg\" %(augmented_path, i)\n",
    "                    transformed_image= rotate(img, angle)\n",
    "                    transformed_image = img_as_ubyte(transformed_image)  #Convert an image to unsigned byte format, with values in [0, 255].\n",
    "                    transformed_image=cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB) #convert image to RGB before saving it\n",
    "                    cv2.imwrite(new_image_path, transformed_image)\n",
    "                elif angle == 90:\n",
    "                    new_image_path= \"%s/rot90_image_%s.jpg\" %(augmented_path, i)\n",
    "                    transformed_image= rotate(img, angle)\n",
    "                    transformed_image = img_as_ubyte(transformed_image)  #Convert an image to unsigned byte format, with values in [0, 255].\n",
    "                    transformed_image=cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB) #convert image to RGB before saving it\n",
    "                    cv2.imwrite(new_image_path, transformed_image)\n",
    "                elif angle == -90:\n",
    "                    new_image_path= \"%s/rot-90_image_%s.jpg\" %(augmented_path, i)\n",
    "                    transformed_image= rotate(img, angle)\n",
    "                    transformed_image = img_as_ubyte(transformed_image)  #Convert an image to unsigned byte format, with values in [0, 255].\n",
    "                    transformed_image=cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB) #convert image to RGB before saving it\n",
    "                    cv2.imwrite(new_image_path, transformed_image)\n",
    "\n",
    "    return 'done'\n",
    "\n",
    "\n",
    "def val_image_gen(name,disease,val,hflip,vflip,rot,angle,copy):\n",
    "    \n",
    "    if val==True:\n",
    "        augmented_path=\"/Users/vivekd/Downloads/d/c/val/\"+name        \n",
    "        for i in range(len(disease)):\n",
    "            img= cv2.imread(disease[i])\n",
    "            img= cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            img= cv2.resize(img,(224,224))\n",
    "            \n",
    "            \n",
    "            if copy==True:\n",
    "                new_image_path= \"%s/original_image_%s.jpg\" %(augmented_path, i)\n",
    "                transformed_image = img_as_ubyte(img)  #Convert an image to unsigned byte format, with values in [0, 255].\n",
    "                transformed_image=cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB) #convert image to RGB before saving it\n",
    "                cv2.imwrite(new_image_path, transformed_image)\n",
    "                            \n",
    "\n",
    "            if hflip==True:\n",
    "                new_image_path= \"%s/hflip_image_%s.jpg\" %(augmented_path, i)\n",
    "                transformed_image= np.fliplr(img)\n",
    "                transformed_image = img_as_ubyte(transformed_image)  #Convert an image to unsigned byte format, with values in [0, 255].\n",
    "                transformed_image=cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB) #convert image to RGB before saving it\n",
    "                cv2.imwrite(new_image_path, transformed_image)\n",
    "\n",
    "            if vflip==True:\n",
    "                new_image_path= \"%s/vflip_image_%s.jpg\" %(augmented_path, i)\n",
    "                transformed_image= np.flipud(img)\n",
    "                transformed_image = img_as_ubyte(transformed_image)  #Convert an image to unsigned byte format, with values in [0, 255].\n",
    "                transformed_image=cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB) #convert image to RGB before saving it\n",
    "                cv2.imwrite(new_image_path, transformed_image)\n",
    "                \n",
    "            if rot==True:\n",
    "                if angle == 180:\n",
    "                    new_image_path= \"%s/rot180_image_%s.jpg\" %(augmented_path, i)\n",
    "                    transformed_image= rotate(img, angle)\n",
    "                    transformed_image = img_as_ubyte(transformed_image)  #Convert an image to unsigned byte format, with values in [0, 255].\n",
    "                    transformed_image=cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB) #convert image to RGB before saving it\n",
    "                    cv2.imwrite(new_image_path, transformed_image)\n",
    "                elif angle == 90:\n",
    "                    new_image_path= \"%s/rot90_image_%s.jpg\" %(augmented_path, i)\n",
    "                    transformed_image= rotate(img, angle)\n",
    "                    transformed_image = img_as_ubyte(transformed_image)  #Convert an image to unsigned byte format, with values in [0, 255].\n",
    "                    transformed_image=cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB) #convert image to RGB before saving it\n",
    "                    cv2.imwrite(new_image_path, transformed_image)\n",
    "                elif angle == -90:\n",
    "                    new_image_path= \"%s/rot-90_image_%s.jpg\" %(augmented_path, i)\n",
    "                    transformed_image= rotate(img, angle)\n",
    "                    transformed_image = img_as_ubyte(transformed_image)  #Convert an image to unsigned byte format, with values in [0, 255].\n",
    "                    transformed_image=cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB) #convert image to RGB before saving it\n",
    "                    cv2.imwrite(new_image_path, transformed_image)\n",
    "                \n",
    "                \n",
    "    return 'done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating images for val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gen(name='akiec',disease=akiec,copy=True,train=True,hflip=True,vflip=True,rot=True,angle=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gen(name='bcc',disease=bcc,copy=True,train=True,hflip=True,vflip=False,rot=False,angle=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gen(name='bcc',disease=bcc[:120],copy=False,train=True,hflip=False,vflip=True,rot=False,angle=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gen(name='bkl',disease=bkl,copy=True,train=True,hflip=False,vflip=False,rot=False,angle=0)\n",
    "image_gen(name='bkl',disease=bkl[:100],copy=False,train=True,hflip=True,vflip=True,rot=False,angle=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gen(name='df',disease=df,copy=True,train=True,hflip=True,vflip=True,rot=True,angle=180)\n",
    "image_gen(name='df',disease=df,copy=False,train=True,hflip=False,vflip=False,rot=True,angle=90)\n",
    "image_gen(name='df',disease=df,copy=False,train=True,hflip=False,vflip=False,rot=True,angle=-90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gen(name='mel',disease=mel,copy=True,train=True,hflip=False,vflip=False,rot=False,angle=0)\n",
    "image_gen(name='mel',disease=mel[:100],copy=False,train=True,hflip=True,vflip=False,rot=False,angle=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gen(name='nv',disease=nv[:1000],copy=True,train=True,hflip=False,vflip=False,rot=False,angle=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gen(name='vasc',disease=vasc,copy=True,train=True,hflip=True,vflip=True,rot=True,angle=180)\n",
    "image_gen(name='vasc',disease=vasc,copy=False,train=True,hflip=False,vflip=False,rot=True,angle=90)\n",
    "image_gen(name='vasc',disease=vasc,copy=False,train=True,hflip=False,vflip=False,rot=True,angle=-90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating images for val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_image_gen(name='akiec',disease=akiec_v,copy=True,val=True,hflip=True,vflip=True,rot=True,angle=180)\n",
    "val_image_gen(name='akiec',disease=akiec_v,copy=False,val=True,hflip=False,vflip=False,rot=True,angle=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_image_gen(name='bcc',disease=bcc_v,copy=True,val=True,hflip=True,vflip=True,rot=False,angle=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_image_gen(name='bkl',disease=bkl_v,copy=True,val=True,hflip=False,vflip=False,rot=False,angle=0)\n",
    "val_image_gen(name='bkl',disease=bkl_v[:100],copy=False,val=True,hflip=True,vflip=False,rot=False,angle=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_image_gen(name='df',disease=df_v,copy=True,val=True,hflip=True,vflip=True,rot=True,angle=180)\n",
    "val_image_gen(name='df',disease=df_v,copy=False,val=True,hflip=False,vflip=False,rot=True,angle=90)\n",
    "val_image_gen(name='df',disease=df_v,copy=False,val=True,hflip=False,vflip=False,rot=True,angle=-90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_image_gen(name='mel',disease=mel_v,copy=True,val=True,hflip=False,vflip=False,rot=False,angle=0)\n",
    "val_image_gen(name='mel',disease=mel_v[:100],copy=True,val=True,hflip=True,vflip=False,rot=False,angle=0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_image_gen(name='nv',disease=nv_v[:300],copy=True,val=True,hflip=False,vflip=False,rot=False,angle=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_image_gen(name='vasc',disease=vasc_v,copy=True,val=True,hflip=True,vflip=True,rot=True,angle=180)\n",
    "val_image_gen(name='vasc',disease=vasc_v,copy=False,val=True,hflip=False,vflip=False,rot=True,angle=90)\n",
    "val_image_gen(name='vasc',disease=vasc_v,copy=False,val=True,hflip=False,vflip=False,rot=True,angle=-90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "drop_out = 0.5\n",
    "activation = 'softmax'\n",
    "classes = 7\n",
    "\n",
    "# below dunno this are default.\n",
    "optimizer='adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "Found 8000 images belonging to 7 classes.\n",
      "[ 4.3956044   2.79427174  1.30314383 12.5588697   1.28410915  0.21314009\n",
      " 10.2960103 ]\n",
      "{0: 4.395604395604396, 1: 2.7942717429269996, 2: 1.3031438345007331, 3: 12.558869701726845, 4: 1.2841091492776886, 5: 0.21314008632173495, 6: 10.296010296010296}\n",
      "class weights with sklearn : {0: 4.395604395604396, 1: 2.7942717429269996, 2: 1.3031438345007331, 3: 12.558869701726845, 4: 1.2841091492776886, 5: 0.21314008632173495, 6: 10.296010296010296}\n",
      "Found 2015 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"unbalanced_data/train\"\n",
    "test_dir = \"unbalanced_data/val\"\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "train_data_dir = train_dir\n",
    "validation_data_dir = test_dir\n",
    "nb_train_samples = 8000\n",
    "nb_validation_samples = 2015\n",
    "\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3 , img_width , img_height)\n",
    "else:\n",
    "\n",
    "    input_shape = (img_width,img_height,3)\n",
    "    \n",
    "print(input_shape)\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale=1. / 255,horizontal_flip=True,vertical_flip=True,rotation_range=180)\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_dir,\n",
    "target_size=(img_width, img_height),\n",
    "batch_size=batch_size,\n",
    "class_mode='categorical')\n",
    "\n",
    "\n",
    "# Calculate class weights\n",
    "# counter = Counter(train_generator.classes)\n",
    "# max_val = float(max(counter.values()))\n",
    "# class_weights = {class_id: max_val/num_images for class_id, num_images in counter.items()}\n",
    "# print(\"class_weights :\" + \"{0: 20.623076923076923, 1: 13.11002444987775, 2: 6.114025085518814, 3: 58.92307692307692, 4: 6.024719101123596, 5: 1.0, 6: 48.306306306306304}\")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "               'balanced',\n",
    "                np.unique(train_generator.classes), \n",
    "                train_generator.classes)\n",
    "print(class_weights)\n",
    "\n",
    "temp = [0,1,2,3,4,5,6]\n",
    "class_weights = dict(zip(temp, class_weights))\n",
    "\n",
    "print(class_weights)\n",
    "\n",
    "print(\"class weights with sklearn : \"  +str(class_weights))\n",
    "\n",
    "\n",
    "# counter = Counter(train_generator.classes)\n",
    "# total = float(sum(counter.values()))\n",
    "# class_weight = {class_id : (1/num_images)*(total)/2.0 for class_id, num_images in counter.items()}\n",
    "\n",
    "# print(class_weights)\n",
    "\n",
    "\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "test_dir,\n",
    "target_size=(img_width, img_height),\n",
    "batch_size=batch_size,\n",
    "class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16():\n",
    "  model1 = Sequential()\n",
    "  checkpoint = ModelCheckpoint(filepath='7balancing with class_weights/vgg16_sklearnB1.h5', mode='max', monitor='val_accuracy', verbose=2, save_best_only=True)\n",
    "  callbacks_list = [checkpoint]\n",
    "  vgg16_model = VGG16(weights='imagenet',include_top=False, input_shape=input_shape)\n",
    "  model1.add(vgg16_model)\n",
    "  model1.add(Flatten())\n",
    "  model1.add(Dropout(drop_out))\n",
    "  model1.add(Dense(classes,activation = activation))\n",
    "  model1.layers[0].trainable = False\n",
    "  model1.summary()\n",
    "  model1.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "  model1.fit(\n",
    "  train_generator,\n",
    "  steps_per_epoch=nb_train_samples // batch_size,\n",
    "  epochs=epochs,\n",
    "  validation_data=validation_generator,\n",
    "  class_weight=class_weights,\n",
    "  validation_steps=nb_validation_samples // batch_size,callbacks = callbacks_list)\n",
    "    \n",
    "    \n",
    "def mobilenet():\n",
    "  model5= Sequential()\n",
    "  checkpoint = ModelCheckpoint(filepath='7balancing with class_weights/mobilenet_B1.h5', mode='max', monitor='val_accuracy', verbose=2, save_best_only=True)\n",
    "  callbacks_list = [checkpoint]\n",
    "  mobilenet_model = MobileNetV2(weights='imagenet',include_top=False, input_shape=input_shape)\n",
    "  model5.add(mobilenet_model)\n",
    "  model5.add(Flatten())\n",
    "  model5.add(Dropout(drop_out))\n",
    "  model5.add(Dense(classes,activation = activation))\n",
    "  model5.layers[0].trainable = False\n",
    "  model5.summary()\n",
    "  model5.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "  model5.fit(\n",
    "  train_generator,\n",
    "  steps_per_epoch=nb_train_samples // batch_size,\n",
    "  epochs=epochs,verbose=1,\n",
    "  validation_data=validation_generator,\n",
    "  class_weight=class_weights,\n",
    "  validation_steps=nb_validation_samples // batch_size,callbacks = callbacks_list)\n",
    "    \n",
    "    \n",
    "def xception():\n",
    "  model7 = Sequential()\n",
    "  checkpoint = ModelCheckpoint(filepath='7balancing with class_weights/xception_B1.h5', mode='max', monitor='val_accuracy', verbose=2, save_best_only=True)\n",
    "  callbacks_list = [checkpoint]\n",
    "  xception_model = Xception(weights='imagenet',include_top=False, input_shape=input_shape)\n",
    "  model7.add(xception_model)\n",
    "  model7.add(Flatten())\n",
    "  model7.add(Dropout(drop_out))\n",
    "  model7.add(Dense(classes,activation = activation))\n",
    "  model7.layers[0].trainable = False\n",
    "  model7.summary()\n",
    "  model7.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "  model7.fit(\n",
    "  train_generator,\n",
    "  steps_per_epoch=nb_train_samples // batch_size,\n",
    "  epochs=epochs,verbose=1,\n",
    "  validation_data=validation_generator,\n",
    "  class_weight=class_weights,\n",
    "  validation_steps=nb_validation_samples // batch_size,callbacks = callbacks_list)\n",
    "    \n",
    "def resnet50():\n",
    "    model2 = Sequential()\n",
    "    checkpoint = ModelCheckpoint(filepath='7withoutbalancing/resnet50_WB1.h5', mode='max', monitor='val_accuracy', verbose=2, save_best_only=True)\n",
    "    callbacks_list = [checkpoint]\n",
    "    resnet_model = ResNet50(weights='imagenet',include_top=False, input_shape=input_shape)\n",
    "    model2.add(resnet_model)\n",
    "    model2.add(Flatten())\n",
    "    model2.add(Dropout(drop_out))\n",
    "    model2.add(Dense(classes,activation = activation))\n",
    "    model2.layers[0].trainable = False\n",
    "    model2.summary()\n",
    "    model2.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    model2.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,callbacks = callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 7)                 175623    \n",
      "=================================================================\n",
      "Total params: 14,890,311\n",
      "Trainable params: 175,623\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 163s 162ms/step - loss: nan - accuracy: 0.0304 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.03337, saving model to 7balancing with class_weights/vgg16_sklearnB1.h5\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: nan - accuracy: 0.0333 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.03337\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: nan - accuracy: 0.0318 - val_loss: nan - val_accuracy: 0.0329\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.03337\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: nan - accuracy: 0.0321 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.03337\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: nan - accuracy: 0.0316 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.03337\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: nan - accuracy: 0.0313 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.03337\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: nan - accuracy: 0.0341 - val_loss: nan - val_accuracy: 0.0329\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.03337\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 162s 161ms/step - loss: nan - accuracy: 0.0328 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.03337\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: nan - accuracy: 0.0319 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.03337\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: nan - accuracy: 0.0337 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.03337\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: nan - accuracy: 0.0328 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.03337\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: nan - accuracy: 0.0327 - val_loss: nan - val_accuracy: 0.0329\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.03337\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: nan - accuracy: 0.0322 - val_loss: nan - val_accuracy: 0.0329\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.03337\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: nan - accuracy: 0.0376 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.03337\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: nan - accuracy: 0.0305 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.03337\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: nan - accuracy: 0.0314 - val_loss: nan - val_accuracy: 0.0329\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.03337\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 163s 163ms/step - loss: nan - accuracy: 0.0330 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.03337\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: nan - accuracy: 0.0329 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.03337\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: nan - accuracy: 0.0338 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.03337\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: nan - accuracy: 0.0318 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.03337\n"
     ]
    }
   ],
   "source": [
    "vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 62720)             0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 62720)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 439047    \n",
      "=================================================================\n",
      "Total params: 2,697,031\n",
      "Trainable params: 439,047\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 69s 67ms/step - loss: nan - accuracy: 0.0315 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.03337, saving model to 7balancing with class_weights/mobilenet_B1.h5\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: nan - accuracy: 0.0326 - val_loss: nan - val_accuracy: 0.0329\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.03337\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: nan - accuracy: 0.0355 - val_loss: nan - val_accuracy: 0.0329\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.03337\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: nan - accuracy: 0.0296 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.03337\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: nan - accuracy: 0.0305 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.03337\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: nan - accuracy: 0.0308 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.03337\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: nan - accuracy: 0.0324 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.03337\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: nan - accuracy: 0.0331 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.03337\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: nan - accuracy: 0.0309 - val_loss: nan - val_accuracy: 0.0329\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.03337\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: nan - accuracy: 0.0325 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.03337\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: nan - accuracy: 0.0328 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.03337\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: nan - accuracy: 0.0345 - val_loss: nan - val_accuracy: 0.0329\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.03337\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: nan - accuracy: 0.0346 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.03337\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: nan - accuracy: 0.0343 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.03337\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 67s 66ms/step - loss: nan - accuracy: 0.0343 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.03337\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: nan - accuracy: 0.0324 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.03337\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: nan - accuracy: 0.0304 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.03337\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: nan - accuracy: 0.0336 - val_loss: nan - val_accuracy: 0.0329\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.03337\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: nan - accuracy: 0.0324 - val_loss: nan - val_accuracy: 0.0329\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.03337\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: nan - accuracy: 0.0308 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.03337\n"
     ]
    }
   ],
   "source": [
    "mobilenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Functional)        (None, 7, 7, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 702471    \n",
      "=================================================================\n",
      "Total params: 21,563,951\n",
      "Trainable params: 702,471\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 148s 146ms/step - loss: nan - accuracy: 0.0338 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.03337, saving model to 7balancing with class_weights/xception_B1.h5\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 143s 143ms/step - loss: nan - accuracy: 0.0315 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.03337\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 142s 142ms/step - loss: nan - accuracy: 0.0333 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.03337\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 143s 143ms/step - loss: nan - accuracy: 0.0326 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.03337\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 143s 143ms/step - loss: nan - accuracy: 0.0296 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.03337\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 143s 143ms/step - loss: nan - accuracy: 0.0324 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.03337\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 143s 143ms/step - loss: nan - accuracy: 0.0338 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.03337\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 143s 143ms/step - loss: nan - accuracy: 0.0312 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.03337\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 143s 143ms/step - loss: nan - accuracy: 0.0333 - val_loss: nan - val_accuracy: 0.0329\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.03337\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 143s 143ms/step - loss: nan - accuracy: 0.0348 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.03337\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 143s 143ms/step - loss: nan - accuracy: 0.0334 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.03337\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 143s 143ms/step - loss: nan - accuracy: 0.0326 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.03337\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 143s 143ms/step - loss: nan - accuracy: 0.0302 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.03337\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 143s 143ms/step - loss: nan - accuracy: 0.0311 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.03337\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 142s 142ms/step - loss: nan - accuracy: 0.0311 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.03337\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 144s 144ms/step - loss: nan - accuracy: 0.0362 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.03337\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 144s 144ms/step - loss: nan - accuracy: 0.0299 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.03337\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 144s 144ms/step - loss: nan - accuracy: 0.0339 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.03337\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 143s 143ms/step - loss: nan - accuracy: 0.0322 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.03337\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 145s 145ms/step - loss: nan - accuracy: 0.0310 - val_loss: nan - val_accuracy: 0.0334\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.03337\n"
     ]
    }
   ],
   "source": [
    "xception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 702471    \n",
      "=================================================================\n",
      "Total params: 24,290,183\n",
      "Trainable params: 702,471\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "250/250 [==============================] - 873s 3s/step - loss: 1.8843 - accuracy: 0.6543 - val_loss: 1.7189 - val_accuracy: 0.6658\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66583, saving model to 7withoutbalancing/resnet50_WB1.h5\n",
      "Epoch 2/20\n",
      " 45/250 [====>.........................] - ETA: 10:23 - loss: 1.7041 - accuracy: 0.6794"
     ]
    }
   ],
   "source": [
    "resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 175623    \n",
      "=================================================================\n",
      "Total params: 14,890,311\n",
      "Trainable params: 175,623\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "250/250 [==============================] - 203s 805ms/step - loss: 1.3063 - accuracy: 0.6247 - val_loss: 0.9441 - val_accuracy: 0.7061\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70615, saving model to vgg16_B1.h5\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 211s 818ms/step - loss: 0.9781 - accuracy: 0.6905 - val_loss: 1.0071 - val_accuracy: 0.6996\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.70615\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 210s 814ms/step - loss: 1.0123 - accuracy: 0.6853 - val_loss: 0.8506 - val_accuracy: 0.7177\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.70615 to 0.71774, saving model to vgg16_B1.h5\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 209s 811ms/step - loss: 0.9307 - accuracy: 0.6978 - val_loss: 0.8211 - val_accuracy: 0.7258\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.71774 to 0.72581, saving model to vgg16_B1.h5\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 211s 819ms/step - loss: 0.9540 - accuracy: 0.6881 - val_loss: 0.8186 - val_accuracy: 0.7384\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.72581 to 0.73841, saving model to vgg16_B1.h5\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 209s 813ms/step - loss: 0.8946 - accuracy: 0.7114 - val_loss: 0.8696 - val_accuracy: 0.7288\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.73841\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 210s 817ms/step - loss: 0.9236 - accuracy: 0.7070 - val_loss: 1.0300 - val_accuracy: 0.7137\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.73841\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 209s 812ms/step - loss: 0.9312 - accuracy: 0.7069 - val_loss: 1.2404 - val_accuracy: 0.6956\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.73841\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 212s 824ms/step - loss: 0.9016 - accuracy: 0.7138 - val_loss: 0.9409 - val_accuracy: 0.7339\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.73841\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 209s 812ms/step - loss: 0.8923 - accuracy: 0.7168 - val_loss: 0.9022 - val_accuracy: 0.7248\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.73841\n",
      "Epoch 11/20\n",
      "250/250 [==============================] - 213s 827ms/step - loss: 0.9059 - accuracy: 0.7231 - val_loss: 0.7917 - val_accuracy: 0.7445\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.73841 to 0.74446, saving model to vgg16_B1.h5\n",
      "Epoch 12/20\n",
      "250/250 [==============================] - 210s 813ms/step - loss: 0.8617 - accuracy: 0.7203 - val_loss: 0.7652 - val_accuracy: 0.7520\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.74446 to 0.75202, saving model to vgg16_B1.h5\n",
      "Epoch 13/20\n",
      "250/250 [==============================] - 210s 817ms/step - loss: 0.8972 - accuracy: 0.7174 - val_loss: 0.9842 - val_accuracy: 0.7258\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75202\n",
      "Epoch 14/20\n",
      "250/250 [==============================] - 209s 812ms/step - loss: 0.8709 - accuracy: 0.7250 - val_loss: 1.0929 - val_accuracy: 0.7077\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75202\n",
      "Epoch 15/20\n",
      "250/250 [==============================] - 211s 820ms/step - loss: 0.9674 - accuracy: 0.7089 - val_loss: 0.9336 - val_accuracy: 0.7167\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75202\n",
      "Epoch 16/20\n",
      "250/250 [==============================] - 211s 817ms/step - loss: 0.8813 - accuracy: 0.7119 - val_loss: 0.8258 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75202\n",
      "Epoch 17/20\n",
      "250/250 [==============================] - 210s 816ms/step - loss: 0.8078 - accuracy: 0.7399 - val_loss: 1.0552 - val_accuracy: 0.7308\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75202\n",
      "Epoch 18/20\n",
      "250/250 [==============================] - 210s 816ms/step - loss: 0.8590 - accuracy: 0.7241 - val_loss: 0.8232 - val_accuracy: 0.7520\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75202\n",
      "Epoch 19/20\n",
      "250/250 [==============================] - 210s 814ms/step - loss: 0.8184 - accuracy: 0.7354 - val_loss: 0.8180 - val_accuracy: 0.7424\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75202\n",
      "Epoch 20/20\n",
      "250/250 [==============================] - 212s 823ms/step - loss: 0.8433 - accuracy: 0.7306 - val_loss: 0.8160 - val_accuracy: 0.7505\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75202\n"
     ]
    }
   ],
   "source": [
    "vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 62720)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 62720)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 439047    \n",
      "=================================================================\n",
      "Total params: 2,697,031\n",
      "Trainable params: 439,047\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "250/250 [==============================] - 69s 264ms/step - loss: 5.5992 - accuracy: 0.6219 - val_loss: 18.3686 - val_accuracy: 0.6658\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66583, saving model to mobilenet_B1.h5\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 63s 250ms/step - loss: 4.8418 - accuracy: 0.6821 - val_loss: 23.0783 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66583 to 0.66784, saving model to mobilenet_B1.h5\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 62s 250ms/step - loss: 5.7269 - accuracy: 0.6886 - val_loss: 23.6744 - val_accuracy: 0.6683\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66784 to 0.66835, saving model to mobilenet_B1.h5\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 63s 250ms/step - loss: 5.8000 - accuracy: 0.7026 - val_loss: 24.0159 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66835\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 6.2222 - accuracy: 0.6936 - val_loss: 28.4033 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.66835\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 63s 250ms/step - loss: 6.4964 - accuracy: 0.7118 - val_loss: 23.8995 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66835\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 7.0133 - accuracy: 0.7045 - val_loss: 32.2913 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66835\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 7.1893 - accuracy: 0.7061 - val_loss: 29.9668 - val_accuracy: 0.6648\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66835\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 7.3706 - accuracy: 0.7090 - val_loss: 32.0537 - val_accuracy: 0.6683\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66835\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 7.2758 - accuracy: 0.7148 - val_loss: 35.0422 - val_accuracy: 0.6648\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66835\n",
      "Epoch 11/20\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 7.1504 - accuracy: 0.7286 - val_loss: 28.1905 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.66835 to 0.66986, saving model to mobilenet_B1.h5\n",
      "Epoch 12/20\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 7.4294 - accuracy: 0.7179 - val_loss: 37.0487 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66986\n",
      "Epoch 13/20\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 7.8264 - accuracy: 0.7170 - val_loss: 32.0063 - val_accuracy: 0.6658\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66986\n",
      "Epoch 14/20\n",
      "250/250 [==============================] - 64s 255ms/step - loss: 7.5835 - accuracy: 0.7367 - val_loss: 37.6427 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66986\n",
      "Epoch 15/20\n",
      "250/250 [==============================] - 64s 255ms/step - loss: 7.8766 - accuracy: 0.7262 - val_loss: 32.5240 - val_accuracy: 0.6689\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66986\n",
      "Epoch 16/20\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 7.7343 - accuracy: 0.7254 - val_loss: 35.9840 - val_accuracy: 0.6653\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.66986\n",
      "Epoch 17/20\n",
      "250/250 [==============================] - 64s 257ms/step - loss: 8.0484 - accuracy: 0.7250 - val_loss: 32.6228 - val_accuracy: 0.6658\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.66986\n",
      "Epoch 18/20\n",
      "250/250 [==============================] - 64s 257ms/step - loss: 8.4293 - accuracy: 0.7244 - val_loss: 42.1885 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.66986\n",
      "Epoch 19/20\n",
      "250/250 [==============================] - 64s 257ms/step - loss: 8.2332 - accuracy: 0.7284 - val_loss: 39.3921 - val_accuracy: 0.6653\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.66986\n",
      "Epoch 20/20\n",
      "250/250 [==============================] - 64s 257ms/step - loss: 8.5257 - accuracy: 0.7352 - val_loss: 37.9713 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.66986\n"
     ]
    }
   ],
   "source": [
    "mobilenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Functional)        (None, 7, 7, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 702471    \n",
      "=================================================================\n",
      "Total params: 21,563,951\n",
      "Trainable params: 702,471\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "250/250 [==============================] - 105s 407ms/step - loss: 1.8858 - accuracy: 0.6537 - val_loss: 1.7196 - val_accuracy: 0.6643\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66431, saving model to xception_B1.h5\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 182s 725ms/step - loss: 1.6672 - accuracy: 0.6733 - val_loss: 1.5376 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66431 to 0.66683, saving model to xception_B1.h5\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 180s 717ms/step - loss: 1.4928 - accuracy: 0.6766 - val_loss: 1.4047 - val_accuracy: 0.6658\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66683\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 179s 718ms/step - loss: 1.3790 - accuracy: 0.6673 - val_loss: 1.3155 - val_accuracy: 0.6638\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66683\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 195s 780ms/step - loss: 1.2850 - accuracy: 0.6709 - val_loss: 1.2488 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.66683 to 0.66734, saving model to xception_B1.h5\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 171s 675ms/step - loss: 1.2370 - accuracy: 0.6681 - val_loss: 1.2105 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.66734\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 111s 443ms/step - loss: 1.1796 - accuracy: 0.6794 - val_loss: 1.1861 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66734\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 290s 1s/step - loss: 1.1698 - accuracy: 0.6728 - val_loss: 1.1712 - val_accuracy: 0.6673\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66734\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 226s 895ms/step - loss: 1.1568 - accuracy: 0.6698 - val_loss: 1.1626 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66734\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 150s 596ms/step - loss: 1.1688 - accuracy: 0.6593 - val_loss: 1.1582 - val_accuracy: 0.6658\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66734\n",
      "Epoch 11/20\n",
      "250/250 [==============================] - 120s 476ms/step - loss: 1.1582 - accuracy: 0.6623 - val_loss: 1.1470 - val_accuracy: 0.6694\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.66734 to 0.66935, saving model to xception_B1.h5\n",
      "Epoch 12/20\n",
      "250/250 [==============================] - 178s 703ms/step - loss: 1.1267 - accuracy: 0.6738 - val_loss: 1.1456 - val_accuracy: 0.6678\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.66935\n",
      "Epoch 13/20\n",
      "250/250 [==============================] - 166s 661ms/step - loss: 1.1426 - accuracy: 0.6675 - val_loss: 1.1464 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66935\n",
      "Epoch 14/20\n",
      "250/250 [==============================] - 126s 504ms/step - loss: 1.1244 - accuracy: 0.6761 - val_loss: 1.1466 - val_accuracy: 0.6658\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66935\n",
      "Epoch 15/20\n",
      "250/250 [==============================] - 191s 764ms/step - loss: 1.1333 - accuracy: 0.6721 - val_loss: 1.1460 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66935\n",
      "Epoch 16/20\n",
      "250/250 [==============================] - 209s 838ms/step - loss: 1.1159 - accuracy: 0.6766 - val_loss: 1.1324 - val_accuracy: 0.6704\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.66935 to 0.67036, saving model to xception_B1.h5\n",
      "Epoch 17/20\n",
      "250/250 [==============================] - 126s 500ms/step - loss: 1.1035 - accuracy: 0.6800 - val_loss: 1.1431 - val_accuracy: 0.6658\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67036\n",
      "Epoch 18/20\n",
      "250/250 [==============================] - 137s 550ms/step - loss: 1.1351 - accuracy: 0.6690 - val_loss: 1.1411 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67036\n",
      "Epoch 19/20\n",
      "250/250 [==============================] - 197s 785ms/step - loss: 1.1109 - accuracy: 0.6819 - val_loss: 1.1404 - val_accuracy: 0.6668\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67036\n",
      "Epoch 20/20\n",
      "250/250 [==============================] - 129s 512ms/step - loss: 1.1264 - accuracy: 0.6720 - val_loss: 1.1448 - val_accuracy: 0.6653\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67036\n"
     ]
    }
   ],
   "source": [
    "xception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 702471    \n",
      "=================================================================\n",
      "Total params: 24,290,183\n",
      "Trainable params: 702,471\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "782/782 [==============================] - 104s 132ms/step - loss: 16.1224 - accuracy: 0.4185 - val_loss: 28.5702 - val_accuracy: 0.0964\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.09635, saving model to resnet50_B1.h5\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 19.7473 - accuracy: 0.5526 - val_loss: 46.1633 - val_accuracy: 0.1557\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.09635 to 0.15573, saving model to resnet50_B1.h5\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 20.1598 - accuracy: 0.5976 - val_loss: 65.6777 - val_accuracy: 0.1562\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.15573 to 0.15625, saving model to resnet50_B1.h5\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 20.8510 - accuracy: 0.6127 - val_loss: 66.8838 - val_accuracy: 0.1562\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.15625\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 21.9864 - accuracy: 0.6353 - val_loss: 82.8372 - val_accuracy: 0.1562\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.15625\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 22.9639 - accuracy: 0.6287 - val_loss: 84.9842 - val_accuracy: 0.1562\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.15625\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 23.3148 - accuracy: 0.6325 - val_loss: 115.4192 - val_accuracy: 0.1557\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.15625\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 24.0851 - accuracy: 0.6671 - val_loss: 143.0828 - val_accuracy: 0.1562\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.15625\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 23.9525 - accuracy: 0.6619 - val_loss: 157.3891 - val_accuracy: 0.1562\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.15625\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 21.9983 - accuracy: 0.6844 - val_loss: 138.5379 - val_accuracy: 0.1562\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.15625\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 22.9980 - accuracy: 0.6820 - val_loss: 139.4376 - val_accuracy: 0.1562\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.15625\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 24.3748 - accuracy: 0.6892 - val_loss: 125.8869 - val_accuracy: 0.1562\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.15625\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 22.8450 - accuracy: 0.6999 - val_loss: 143.3965 - val_accuracy: 0.1562\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.15625\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - 102s 131ms/step - loss: 22.6581 - accuracy: 0.7049 - val_loss: 120.0060 - val_accuracy: 0.1682\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.15625 to 0.16823, saving model to resnet50_B1.h5\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 22.1272 - accuracy: 0.7047 - val_loss: 116.6015 - val_accuracy: 0.1437\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.16823\n",
      "Epoch 16/20\n",
      "782/782 [==============================] - 101s 130ms/step - loss: 23.7720 - accuracy: 0.7160 - val_loss: 137.5833 - val_accuracy: 0.1557\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.16823\n",
      "Epoch 17/20\n",
      "782/782 [==============================] - 101s 130ms/step - loss: 23.3128 - accuracy: 0.7099 - val_loss: 132.4168 - val_accuracy: 0.1599\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.16823\n",
      "Epoch 18/20\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 24.4312 - accuracy: 0.7124 - val_loss: 149.9878 - val_accuracy: 0.1677\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.16823\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 24.3021 - accuracy: 0.7055 - val_loss: 147.3243 - val_accuracy: 0.1557\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.16823\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 24.6581 - accuracy: 0.7170 - val_loss: 149.7132 - val_accuracy: 0.1542\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.16823\n"
     ]
    }
   ],
   "source": [
    "resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
